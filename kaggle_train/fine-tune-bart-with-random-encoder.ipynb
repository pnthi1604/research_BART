{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8492376,"sourceType":"datasetVersion","datasetId":5066781},{"sourceId":8498896,"sourceType":"datasetVersion","datasetId":5071651},{"sourceId":8515615,"sourceType":"datasetVersion","datasetId":5084029}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/pnthi1604/research_BART\n!pip install torcheval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-25T18:31:45.192435Z","iopub.execute_input":"2024-05-25T18:31:45.193827Z","iopub.status.idle":"2024-05-25T18:32:05.269787Z","shell.execute_reply.started":"2024-05-25T18:31:45.193776Z","shell.execute_reply":"2024-05-25T18:32:05.268122Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'research_BART'...\nremote: Enumerating objects: 791, done.\u001b[K\nremote: Counting objects: 100% (211/211), done.\u001b[K\nremote: Compressing objects: 100% (139/139), done.\u001b[K\nremote: Total 791 (delta 139), reused 139 (delta 72), pack-reused 580\u001b[K\nReceiving objects: 100% (791/791), 447.74 KiB | 12.44 MiB/s, done.\nResolving deltas: 100% (506/506), done.\nCollecting torcheval\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.9.0)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n","output_type":"stream"}]},{"cell_type":"code","source":"from research_BART import train, test, config","metadata":{"execution":{"iopub.status.busy":"2024-05-25T18:32:05.273236Z","iopub.execute_input":"2024-05-25T18:32:05.273709Z","iopub.status.idle":"2024-05-25T18:32:18.597705Z","shell.execute_reply.started":"2024-05-25T18:32:05.273664Z","shell.execute_reply":"2024-05-25T18:32:18.596314Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# const\nBART = \"bart\"\nBART_WITH_EMBEDDING = \"bart_with_embedding\"\nFINE_TUNE_BART_WITH_RANDOM_ENCODER = \"fine_tune_bart_with_random_encoder\"\nFIRST_STEP = \"FIRST\"\nSECOND_STEP = \"SECOND\"","metadata":{"execution":{"iopub.status.busy":"2024-05-25T18:32:18.599411Z","iopub.execute_input":"2024-05-25T18:32:18.600108Z","iopub.status.idle":"2024-05-25T18:32:18.606363Z","shell.execute_reply.started":"2024-05-25T18:32:18.600074Z","shell.execute_reply":"2024-05-25T18:32:18.605250Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"cf = config.get_config(\"/kaggle/working\")\ncf[\"tokenizer_src\"] = \"/kaggle/input/6-dataset/tokenizer/tokenizer_src.json\"\ncf[\"tokenizer_tgt\"] = \"/kaggle/input/1m-mask-vi-and-vi-ds/tokenizer/tokenizer_tgt.json\"\ncf[\"train_ds\"] = \"/kaggle/input/6-dataset/train.csv\"\ncf[\"test_ds\"] = \"/kaggle/input/6-dataset/test.csv\"\ncf[\"batch_train\"] = cf[\"batch_val\"] = 32\ncf[\"model_train\"] = FINE_TUNE_BART_WITH_RANDOM_ENCODER\ncf[\"use_pytorch_metric\"] = True\ncf[\"step_train\"] = FIRST_STEP\ncf[\"num_steps\"] = 15000\ncf[\"val_steps\"] = 1500\ncf[\"lr\"] = 0.3\ncf[\"dropout\"] = 0.1\ncf[\"init_type\"] = \"xavier\"\ncf[\"checkpoint\"] = \"/kaggle/input/pretrained-dataset-90k-step/90k_step/model/model_0000090000.pt\"\ncf","metadata":{"execution":{"iopub.status.busy":"2024-05-25T18:32:18.609684Z","iopub.execute_input":"2024-05-25T18:32:18.610096Z","iopub.status.idle":"2024-05-25T18:32:18.628940Z","shell.execute_reply.started":"2024-05-25T18:32:18.610064Z","shell.execute_reply":"2024-05-25T18:32:18.627595Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'base_dir': '/kaggle/working',\n 'tokenizer_tgt': '/kaggle/input/1m-mask-vi-and-vi-ds/tokenizer/tokenizer_tgt.json',\n 'tokenizer_src': '/kaggle/input/6-dataset/tokenizer/tokenizer_src.json',\n 'use_tokenizer': 'huggingface',\n 'special_tokens': ['<s>', '</s>', '<pad>', '<unk>', '<mask>'],\n 'vocab_size': 30000,\n 'min_frequency': 2,\n 'model_folder': '/kaggle/working/model',\n 'model_basename': 'model_',\n 'model_bart_basename': 'bart_model_',\n 'model_inputs_embeds': 'inputs_embeds_',\n 'model_decoder_inputs_embeds': 'decoder_inputs_embeds_',\n 'model_out': 'out_',\n 'preload': 'latest',\n 'data': '/kaggle/working/data',\n 'log_dir': '/kaggle/working/log',\n 'log_files': '/kaggle/working/log/log_files',\n 'loss_train': '/kaggle/working/log/log_files/loss_train.json',\n 'loss_val': '/kaggle/working/log/log_files/loss_val.json',\n 'loss_train_step': '/kaggle/working/log/log_files/loss_train_step.json',\n 'loss_val_step': '/kaggle/working/log/log_files/loss_val_step.json',\n 'learning_rate_step': '/kaggle/working/log/log_files/learning_rate_step.json',\n 'timestep_train': '/kaggle/working/log/log_files/timestep_train.json',\n 'timestep_val': '/kaggle/working/log/log_files/timestep_val.json',\n 'timestep_train_and_val': '/kaggle/working/log/log_files/timestep_train_and_val.json',\n 'timestep_lr': '/kaggle/working/log/log_files/timestep_lr.json',\n 'lang_src': 'noise_vi',\n 'lang_tgt': 'vi',\n 'train_ds': '/kaggle/input/6-dataset/train.csv',\n 'val_ds': None,\n 'test_ds': '/kaggle/input/6-dataset/test.csv',\n 'corpus': None,\n 'max_len': 100,\n 'model_train': 'fine_tune_bart_with_random_encoder',\n 'step_train': 'FIRST',\n 'pretrain': False,\n 'continue_step': False,\n 'batch_train': 32,\n 'batch_val': 32,\n 'batch_test': 1,\n 'num_steps': 15000,\n 'val_steps': 1500,\n 'd_model': 768,\n 'encoder_layers': 6,\n 'decoder_layers': 6,\n 'encoder_attention_heads': 12,\n 'decoder_attention_heads': 12,\n 'decoder_ffn_dim': 3072,\n 'encoder_ffn_dim': 3072,\n 'activation_function': 'gelu',\n 'dropout': 0.1,\n 'attention_dropout': 0.1,\n 'activation_dropout': 0.1,\n 'classifier_dropout': 0.0,\n 'max_position_embeddings': 100,\n 'init_std': 0.02,\n 'encoder_layerdrop': 0.0,\n 'decoder_layerdrop': 0.0,\n 'scale_embedding': False,\n 'num_beams': 4,\n 'init_type': 'xavier',\n 'share_tgt_emb_and_out': False,\n 'checkpoint': '/kaggle/input/pretrained-dataset-90k-step/90k_step/model/model_0000090000.pt',\n 'weight_decay': 0.0,\n 'lr': 0.3,\n 'eps': 1e-09,\n 'betas': (0.9, 0.98),\n 'label_smoothing': 0.01,\n 'warmup_steps': 4000,\n 'device': 'cpu',\n 'f_beta': 0.5,\n 'beams': [2],\n 'use_pytorch_metric': True}"},"metadata":{}}]},{"cell_type":"code","source":"train.train(cf)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T18:32:18.630364Z","iopub.execute_input":"2024-05-25T18:32:18.630783Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Created:\n/kaggle/working/model\n/kaggle/working/log\n/kaggle/working/log/log_files\n====================================\n/kaggle/input/6-dataset/tokenizer/tokenizer_src.json\n/kaggle/input/1m-mask-vi-and-vi-ds/tokenizer/tokenizer_tgt.json\nRead tokenizer successfully\nVocab size src:  25000\nVocab size tgt:  50000\n====================================\ninputs_embeds.weight\nrandom_encoder.embed_tokens.weight\nrandom_encoder.embed_positions.weight\nrandom_encoder.layers.0.self_attn.k_proj.weight\nrandom_encoder.layers.0.self_attn.k_proj.bias\nrandom_encoder.layers.0.self_attn.v_proj.weight\nrandom_encoder.layers.0.self_attn.v_proj.bias\nrandom_encoder.layers.0.self_attn.q_proj.weight\nrandom_encoder.layers.0.self_attn.q_proj.bias\nrandom_encoder.layers.0.self_attn.out_proj.weight\nrandom_encoder.layers.0.self_attn.out_proj.bias\nrandom_encoder.layers.0.self_attn_layer_norm.weight\nrandom_encoder.layers.0.self_attn_layer_norm.bias\nrandom_encoder.layers.0.fc1.weight\nrandom_encoder.layers.0.fc1.bias\nrandom_encoder.layers.0.fc2.weight\nrandom_encoder.layers.0.fc2.bias\nrandom_encoder.layers.0.final_layer_norm.weight\nrandom_encoder.layers.0.final_layer_norm.bias\nrandom_encoder.layers.1.self_attn.k_proj.weight\nrandom_encoder.layers.1.self_attn.k_proj.bias\nrandom_encoder.layers.1.self_attn.v_proj.weight\nrandom_encoder.layers.1.self_attn.v_proj.bias\nrandom_encoder.layers.1.self_attn.q_proj.weight\nrandom_encoder.layers.1.self_attn.q_proj.bias\nrandom_encoder.layers.1.self_attn.out_proj.weight\nrandom_encoder.layers.1.self_attn.out_proj.bias\nrandom_encoder.layers.1.self_attn_layer_norm.weight\nrandom_encoder.layers.1.self_attn_layer_norm.bias\nrandom_encoder.layers.1.fc1.weight\nrandom_encoder.layers.1.fc1.bias\nrandom_encoder.layers.1.fc2.weight\nrandom_encoder.layers.1.fc2.bias\nrandom_encoder.layers.1.final_layer_norm.weight\nrandom_encoder.layers.1.final_layer_norm.bias\nrandom_encoder.layers.2.self_attn.k_proj.weight\nrandom_encoder.layers.2.self_attn.k_proj.bias\nrandom_encoder.layers.2.self_attn.v_proj.weight\nrandom_encoder.layers.2.self_attn.v_proj.bias\nrandom_encoder.layers.2.self_attn.q_proj.weight\nrandom_encoder.layers.2.self_attn.q_proj.bias\nrandom_encoder.layers.2.self_attn.out_proj.weight\nrandom_encoder.layers.2.self_attn.out_proj.bias\nrandom_encoder.layers.2.self_attn_layer_norm.weight\nrandom_encoder.layers.2.self_attn_layer_norm.bias\nrandom_encoder.layers.2.fc1.weight\nrandom_encoder.layers.2.fc1.bias\nrandom_encoder.layers.2.fc2.weight\nrandom_encoder.layers.2.fc2.bias\nrandom_encoder.layers.2.final_layer_norm.weight\nrandom_encoder.layers.2.final_layer_norm.bias\nrandom_encoder.layers.3.self_attn.k_proj.weight\nrandom_encoder.layers.3.self_attn.k_proj.bias\nrandom_encoder.layers.3.self_attn.v_proj.weight\nrandom_encoder.layers.3.self_attn.v_proj.bias\nrandom_encoder.layers.3.self_attn.q_proj.weight\nrandom_encoder.layers.3.self_attn.q_proj.bias\nrandom_encoder.layers.3.self_attn.out_proj.weight\nrandom_encoder.layers.3.self_attn.out_proj.bias\nrandom_encoder.layers.3.self_attn_layer_norm.weight\nrandom_encoder.layers.3.self_attn_layer_norm.bias\nrandom_encoder.layers.3.fc1.weight\nrandom_encoder.layers.3.fc1.bias\nrandom_encoder.layers.3.fc2.weight\nrandom_encoder.layers.3.fc2.bias\nrandom_encoder.layers.3.final_layer_norm.weight\nrandom_encoder.layers.3.final_layer_norm.bias\nrandom_encoder.layers.4.self_attn.k_proj.weight\nrandom_encoder.layers.4.self_attn.k_proj.bias\nrandom_encoder.layers.4.self_attn.v_proj.weight\nrandom_encoder.layers.4.self_attn.v_proj.bias\nrandom_encoder.layers.4.self_attn.q_proj.weight\nrandom_encoder.layers.4.self_attn.q_proj.bias\nrandom_encoder.layers.4.self_attn.out_proj.weight\nrandom_encoder.layers.4.self_attn.out_proj.bias\nrandom_encoder.layers.4.self_attn_layer_norm.weight\nrandom_encoder.layers.4.self_attn_layer_norm.bias\nrandom_encoder.layers.4.fc1.weight\nrandom_encoder.layers.4.fc1.bias\nrandom_encoder.layers.4.fc2.weight\nrandom_encoder.layers.4.fc2.bias\nrandom_encoder.layers.4.final_layer_norm.weight\nrandom_encoder.layers.4.final_layer_norm.bias\nrandom_encoder.layers.5.self_attn.k_proj.weight\nrandom_encoder.layers.5.self_attn.k_proj.bias\nrandom_encoder.layers.5.self_attn.v_proj.weight\nrandom_encoder.layers.5.self_attn.v_proj.bias\nrandom_encoder.layers.5.self_attn.q_proj.weight\nrandom_encoder.layers.5.self_attn.q_proj.bias\nrandom_encoder.layers.5.self_attn.out_proj.weight\nrandom_encoder.layers.5.self_attn.out_proj.bias\nrandom_encoder.layers.5.self_attn_layer_norm.weight\nrandom_encoder.layers.5.self_attn_layer_norm.bias\nrandom_encoder.layers.5.fc1.weight\nrandom_encoder.layers.5.fc1.bias\nrandom_encoder.layers.5.fc2.weight\nrandom_encoder.layers.5.fc2.bias\nrandom_encoder.layers.5.final_layer_norm.weight\nrandom_encoder.layers.5.final_layer_norm.bias\nrandom_encoder.layernorm_embedding.weight\nrandom_encoder.layernorm_embedding.bias\nbart_model.encoder.embed_positions.weight\nbart_model.encoder.layers.0.self_attn.k_proj.weight\nbart_model.encoder.layers.0.self_attn.k_proj.bias\nbart_model.encoder.layers.0.self_attn.v_proj.weight\nbart_model.encoder.layers.0.self_attn.v_proj.bias\nbart_model.encoder.layers.0.self_attn.q_proj.weight\nbart_model.encoder.layers.0.self_attn.q_proj.bias\nbart_model.encoder.layers.0.self_attn.out_proj.weight\nbart_model.encoder.layers.0.self_attn.out_proj.bias\nout.weight\nout.bias\nweight\nembed_tokens.weight\nembed_positions.weight\nlayers.0.self_attn.k_proj.weight\nlayers.0.self_attn.k_proj.bias\nlayers.0.self_attn.v_proj.weight\nlayers.0.self_attn.v_proj.bias\nlayers.0.self_attn.q_proj.weight\nlayers.0.self_attn.q_proj.bias\nlayers.0.self_attn.out_proj.weight\nlayers.0.self_attn.out_proj.bias\nlayers.0.self_attn_layer_norm.weight\nlayers.0.self_attn_layer_norm.bias\nlayers.0.fc1.weight\nlayers.0.fc1.bias\nlayers.0.fc2.weight\nlayers.0.fc2.bias\nlayers.0.final_layer_norm.weight\nlayers.0.final_layer_norm.bias\nlayers.1.self_attn.k_proj.weight\nlayers.1.self_attn.k_proj.bias\nlayers.1.self_attn.v_proj.weight\nlayers.1.self_attn.v_proj.bias\nlayers.1.self_attn.q_proj.weight\nlayers.1.self_attn.q_proj.bias\nlayers.1.self_attn.out_proj.weight\nlayers.1.self_attn.out_proj.bias\nlayers.1.self_attn_layer_norm.weight\nlayers.1.self_attn_layer_norm.bias\nlayers.1.fc1.weight\nlayers.1.fc1.bias\nlayers.1.fc2.weight\nlayers.1.fc2.bias\nlayers.1.final_layer_norm.weight\nlayers.1.final_layer_norm.bias\nlayers.2.self_attn.k_proj.weight\nlayers.2.self_attn.k_proj.bias\nlayers.2.self_attn.v_proj.weight\nlayers.2.self_attn.v_proj.bias\nlayers.2.self_attn.q_proj.weight\nlayers.2.self_attn.q_proj.bias\nlayers.2.self_attn.out_proj.weight\nlayers.2.self_attn.out_proj.bias\nlayers.2.self_attn_layer_norm.weight\nlayers.2.self_attn_layer_norm.bias\nlayers.2.fc1.weight\nlayers.2.fc1.bias\nlayers.2.fc2.weight\nlayers.2.fc2.bias\nlayers.2.final_layer_norm.weight\nlayers.2.final_layer_norm.bias\nlayers.3.self_attn.k_proj.weight\nlayers.3.self_attn.k_proj.bias\nlayers.3.self_attn.v_proj.weight\nlayers.3.self_attn.v_proj.bias\nlayers.3.self_attn.q_proj.weight\nlayers.3.self_attn.q_proj.bias\nlayers.3.self_attn.out_proj.weight\nlayers.3.self_attn.out_proj.bias\nlayers.3.self_attn_layer_norm.weight\nlayers.3.self_attn_layer_norm.bias\nlayers.3.fc1.weight\nlayers.3.fc1.bias\nlayers.3.fc2.weight\nlayers.3.fc2.bias\nlayers.3.final_layer_norm.weight\nlayers.3.final_layer_norm.bias\nlayers.4.self_attn.k_proj.weight\nlayers.4.self_attn.k_proj.bias\nlayers.4.self_attn.v_proj.weight\nlayers.4.self_attn.v_proj.bias\nlayers.4.self_attn.q_proj.weight\nlayers.4.self_attn.q_proj.bias\nlayers.4.self_attn.out_proj.weight\nlayers.4.self_attn.out_proj.bias\nlayers.4.self_attn_layer_norm.weight\nlayers.4.self_attn_layer_norm.bias\nlayers.4.fc1.weight\nlayers.4.fc1.bias\nlayers.4.fc2.weight\nlayers.4.fc2.bias\nlayers.4.final_layer_norm.weight\nlayers.4.final_layer_norm.bias\nlayers.5.self_attn.k_proj.weight\nlayers.5.self_attn.k_proj.bias\nlayers.5.self_attn.v_proj.weight\nlayers.5.self_attn.v_proj.bias\nlayers.5.self_attn.q_proj.weight\nlayers.5.self_attn.q_proj.bias\nlayers.5.self_attn.out_proj.weight\nlayers.5.self_attn.out_proj.bias\nlayers.5.self_attn_layer_norm.weight\nlayers.5.self_attn_layer_norm.bias\nlayers.5.fc1.weight\nlayers.5.fc1.bias\nlayers.5.fc2.weight\nlayers.5.fc2.bias\nlayers.5.final_layer_norm.weight\nlayers.5.final_layer_norm.bias\nlayernorm_embedding.weight\nlayernorm_embedding.bias\nweight\nweight\n0.self_attn.k_proj.weight\n0.self_attn.k_proj.bias\n0.self_attn.v_proj.weight\n0.self_attn.v_proj.bias\n0.self_attn.q_proj.weight\n0.self_attn.q_proj.bias\n0.self_attn.out_proj.weight\n0.self_attn.out_proj.bias\n0.self_attn_layer_norm.weight\n0.self_attn_layer_norm.bias\n0.fc1.weight\n0.fc1.bias\n0.fc2.weight\n0.fc2.bias\n0.final_layer_norm.weight\n0.final_layer_norm.bias\n1.self_attn.k_proj.weight\n1.self_attn.k_proj.bias\n1.self_attn.v_proj.weight\n1.self_attn.v_proj.bias\n1.self_attn.q_proj.weight\n1.self_attn.q_proj.bias\n1.self_attn.out_proj.weight\n1.self_attn.out_proj.bias\n1.self_attn_layer_norm.weight\n1.self_attn_layer_norm.bias\n1.fc1.weight\n1.fc1.bias\n1.fc2.weight\n1.fc2.bias\n1.final_layer_norm.weight\n1.final_layer_norm.bias\n2.self_attn.k_proj.weight\n2.self_attn.k_proj.bias\n2.self_attn.v_proj.weight\n2.self_attn.v_proj.bias\n2.self_attn.q_proj.weight\n2.self_attn.q_proj.bias\n2.self_attn.out_proj.weight\n2.self_attn.out_proj.bias\n2.self_attn_layer_norm.weight\n2.self_attn_layer_norm.bias\n2.fc1.weight\n2.fc1.bias\n2.fc2.weight\n2.fc2.bias\n2.final_layer_norm.weight\n2.final_layer_norm.bias\n3.self_attn.k_proj.weight\n3.self_attn.k_proj.bias\n3.self_attn.v_proj.weight\n3.self_attn.v_proj.bias\n3.self_attn.q_proj.weight\n3.self_attn.q_proj.bias\n3.self_attn.out_proj.weight\n3.self_attn.out_proj.bias\n3.self_attn_layer_norm.weight\n3.self_attn_layer_norm.bias\n3.fc1.weight\n3.fc1.bias\n3.fc2.weight\n3.fc2.bias\n3.final_layer_norm.weight\n3.final_layer_norm.bias\n4.self_attn.k_proj.weight\n4.self_attn.k_proj.bias\n4.self_attn.v_proj.weight\n4.self_attn.v_proj.bias\n4.self_attn.q_proj.weight\n4.self_attn.q_proj.bias\n4.self_attn.out_proj.weight\n4.self_attn.out_proj.bias\n4.self_attn_layer_norm.weight\n4.self_attn_layer_norm.bias\n4.fc1.weight\n4.fc1.bias\n4.fc2.weight\n4.fc2.bias\n4.final_layer_norm.weight\n4.final_layer_norm.bias\n5.self_attn.k_proj.weight\n5.self_attn.k_proj.bias\n5.self_attn.v_proj.weight\n5.self_attn.v_proj.bias\n5.self_attn.q_proj.weight\n5.self_attn.q_proj.bias\n5.self_attn.out_proj.weight\n5.self_attn.out_proj.bias\n5.self_attn_layer_norm.weight\n5.self_attn_layer_norm.bias\n5.fc1.weight\n5.fc1.bias\n5.fc2.weight\n5.fc2.bias\n5.final_layer_norm.weight\n5.final_layer_norm.bias\nself_attn.k_proj.weight\nself_attn.k_proj.bias\nself_attn.v_proj.weight\nself_attn.v_proj.bias\nself_attn.q_proj.weight\nself_attn.q_proj.bias\nself_attn.out_proj.weight\nself_attn.out_proj.bias\nself_attn_layer_norm.weight\nself_attn_layer_norm.bias\nfc1.weight\nfc1.bias\nfc2.weight\nfc2.bias\nfinal_layer_norm.weight\nfinal_layer_norm.bias\nk_proj.weight\nk_proj.bias\nv_proj.weight\nv_proj.bias\nq_proj.weight\nq_proj.bias\nout_proj.weight\nout_proj.bias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nself_attn.k_proj.weight\nself_attn.k_proj.bias\nself_attn.v_proj.weight\nself_attn.v_proj.bias\nself_attn.q_proj.weight\nself_attn.q_proj.bias\nself_attn.out_proj.weight\nself_attn.out_proj.bias\nself_attn_layer_norm.weight\nself_attn_layer_norm.bias\nfc1.weight\nfc1.bias\nfc2.weight\nfc2.bias\nfinal_layer_norm.weight\nfinal_layer_norm.bias\nk_proj.weight\nk_proj.bias\nv_proj.weight\nv_proj.bias\nq_proj.weight\nq_proj.bias\nout_proj.weight\nout_proj.bias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nself_attn.k_proj.weight\nself_attn.k_proj.bias\nself_attn.v_proj.weight\nself_attn.v_proj.bias\nself_attn.q_proj.weight\nself_attn.q_proj.bias\nself_attn.out_proj.weight\nself_attn.out_proj.bias\nself_attn_layer_norm.weight\nself_attn_layer_norm.bias\nfc1.weight\nfc1.bias\nfc2.weight\nfc2.bias\nfinal_layer_norm.weight\nfinal_layer_norm.bias\nk_proj.weight\nk_proj.bias\nv_proj.weight\nv_proj.bias\nq_proj.weight\nq_proj.bias\nout_proj.weight\nout_proj.bias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nself_attn.k_proj.weight\nself_attn.k_proj.bias\nself_attn.v_proj.weight\nself_attn.v_proj.bias\nself_attn.q_proj.weight\nself_attn.q_proj.bias\nself_attn.out_proj.weight\nself_attn.out_proj.bias\nself_attn_layer_norm.weight\nself_attn_layer_norm.bias\nfc1.weight\nfc1.bias\nfc2.weight\nfc2.bias\nfinal_layer_norm.weight\nfinal_layer_norm.bias\nk_proj.weight\nk_proj.bias\nv_proj.weight\nv_proj.bias\nq_proj.weight\nq_proj.bias\nout_proj.weight\nout_proj.bias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nself_attn.k_proj.weight\nself_attn.k_proj.bias\nself_attn.v_proj.weight\nself_attn.v_proj.bias\nself_attn.q_proj.weight\nself_attn.q_proj.bias\nself_attn.out_proj.weight\nself_attn.out_proj.bias\nself_attn_layer_norm.weight\nself_attn_layer_norm.bias\nfc1.weight\nfc1.bias\nfc2.weight\nfc2.bias\nfinal_layer_norm.weight\nfinal_layer_norm.bias\nk_proj.weight\nk_proj.bias\nv_proj.weight\nv_proj.bias\nq_proj.weight\nq_proj.bias\nout_proj.weight\nout_proj.bias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nself_attn.k_proj.weight\nself_attn.k_proj.bias\nself_attn.v_proj.weight\nself_attn.v_proj.bias\nself_attn.q_proj.weight\nself_attn.q_proj.bias\nself_attn.out_proj.weight\nself_attn.out_proj.bias\nself_attn_layer_norm.weight\nself_attn_layer_norm.bias\nfc1.weight\nfc1.bias\nfc2.weight\nfc2.bias\nfinal_layer_norm.weight\nfinal_layer_norm.bias\nk_proj.weight\nk_proj.bias\nv_proj.weight\nv_proj.bias\nq_proj.weight\nq_proj.bias\nout_proj.weight\nout_proj.bias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nencoder.embed_positions.weight\nencoder.layers.0.self_attn.k_proj.weight\nencoder.layers.0.self_attn.k_proj.bias\nencoder.layers.0.self_attn.v_proj.weight\nencoder.layers.0.self_attn.v_proj.bias\nencoder.layers.0.self_attn.q_proj.weight\nencoder.layers.0.self_attn.q_proj.bias\nencoder.layers.0.self_attn.out_proj.weight\nencoder.layers.0.self_attn.out_proj.bias\nembed_positions.weight\nlayers.0.self_attn.k_proj.weight\nlayers.0.self_attn.k_proj.bias\nlayers.0.self_attn.v_proj.weight\nlayers.0.self_attn.v_proj.bias\nlayers.0.self_attn.q_proj.weight\nlayers.0.self_attn.q_proj.bias\nlayers.0.self_attn.out_proj.weight\nlayers.0.self_attn.out_proj.bias\nweight\n0.self_attn.k_proj.weight\n0.self_attn.k_proj.bias\n0.self_attn.v_proj.weight\n0.self_attn.v_proj.bias\n0.self_attn.q_proj.weight\n0.self_attn.q_proj.bias\n0.self_attn.out_proj.weight\n0.self_attn.out_proj.bias\nself_attn.k_proj.weight\nself_attn.k_proj.bias\nself_attn.v_proj.weight\nself_attn.v_proj.bias\nself_attn.q_proj.weight\nself_attn.q_proj.bias\nself_attn.out_proj.weight\nself_attn.out_proj.bias\nk_proj.weight\nk_proj.bias\nv_proj.weight\nv_proj.bias\nq_proj.weight\nq_proj.bias\nout_proj.weight\nout_proj.bias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\nweight\nbias\n/kaggle/input/6-dataset/tokenizer/tokenizer_src.json\n/kaggle/input/1m-mask-vi-and-vi-ds/tokenizer/tokenizer_tgt.json\nRead tokenizer successfully\nVocab size src:  25000\nVocab size tgt:  50000\n====================================\nRead dataset successfully\nLength train dataset:  225000\nLength val dataset:  25000\nLength test dataset:  3131\n====================================\nGet dataloader successfully\nNo model to preload, start training from scratch\n/kaggle/input/6-dataset/tokenizer/tokenizer_src.json\n/kaggle/input/1m-mask-vi-and-vi-ds/tokenizer/tokenizer_tgt.json\nRead tokenizer successfully\nVocab size src:  25000\nVocab size tgt:  50000\n====================================\nRead dataset successfully\nLength train dataset:  225000\nLength val dataset:  25000\nLength test dataset:  3131\n====================================\nGet dataloader successfully\n","output_type":"stream"},{"name":"stderr","text":"Trainning:   0%|          | 1/7032 [00:29<57:25:23, 29.40s/it, loss=5.736, global_step=0000000000]","output_type":"stream"}]},{"cell_type":"code","source":"cf[\"continue_step\"] = True\ncf[\"step_train\"] = SECOND_STEP\ncf[\"num_steps\"] += 500","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.train(cf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.test(cf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}