{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8478466,"sourceType":"datasetVersion","datasetId":5056645}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":6136.526082,"end_time":"2024-05-20T04:06:46.661594","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-20T02:24:30.135512","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/pnthi1604/vn_spelling_correction_bart_model","metadata":{"papermill":{"duration":1.440018,"end_time":"2024-05-20T02:24:34.265450","exception":false,"start_time":"2024-05-20T02:24:32.825432","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T16:54:19.853888Z","iopub.execute_input":"2024-05-22T16:54:19.854166Z","iopub.status.idle":"2024-05-22T16:54:21.371562Z","shell.execute_reply.started":"2024-05-22T16:54:19.854140Z","shell.execute_reply":"2024-05-22T16:54:21.370511Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'vn_spelling_correction_bart_model'...\nremote: Enumerating objects: 550, done.\u001b[K\nremote: Counting objects: 100% (177/177), done.\u001b[K\nremote: Compressing objects: 100% (125/125), done.\u001b[K\nremote: Total 550 (delta 102), reused 125 (delta 52), pack-reused 373\u001b[K\nReceiving objects: 100% (550/550), 330.77 KiB | 11.03 MiB/s, done.\nResolving deltas: 100% (334/334), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torcheval","metadata":{"execution":{"iopub.status.busy":"2024-05-22T16:54:21.373990Z","iopub.execute_input":"2024-05-22T16:54:21.374396Z","iopub.status.idle":"2024-05-22T16:54:34.891977Z","shell.execute_reply.started":"2024-05-22T16:54:21.374357Z","shell.execute_reply":"2024-05-22T16:54:34.891049Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torcheval\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.9.0)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n","output_type":"stream"}]},{"cell_type":"code","source":"from vn_spelling_correction_bart_model import train, test, config","metadata":{"papermill":{"duration":9.831611,"end_time":"2024-05-20T02:24:44.100479","exception":false,"start_time":"2024-05-20T02:24:34.268868","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T16:54:34.893299Z","iopub.execute_input":"2024-05-22T16:54:34.893595Z","iopub.status.idle":"2024-05-22T16:54:45.219535Z","shell.execute_reply.started":"2024-05-22T16:54:34.893550Z","shell.execute_reply":"2024-05-22T16:54:45.218560Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"cf = config.get_config(\"/kaggle/working\")\ncf[\"tokenizer_src\"] = \"/kaggle/input/2-ds-pretrain-model-bart/tokenizer/tokenizer_src.json\"\ncf[\"tokenizer_tgt\"] = \"/kaggle/input/2-ds-pretrain-model-bart/tokenizer/tokenizer_tgt.json\"\ncf[\"model_train\"] = \"bart\"\ncf[\"train_ds\"] = \"/kaggle/input/2-ds-pretrain-model-bart/train.csv\"\ncf[\"use_tokenizer\"] = \"wordlevel\"\ncf[\"num_steps\"] = 60000\ncf[\"pretrain\"] = True\ncf[\"val_steps\"] = cf[\"num_steps\"] // 50\ncf[\"batch_train\"] = cf[\"batch_val\"] = 28\ncf[\"dropout\"] = 0.15\ncf[\"lr\"] = 0.3\ncf","metadata":{"papermill":{"duration":0.061453,"end_time":"2024-05-20T02:24:44.164928","exception":false,"start_time":"2024-05-20T02:24:44.103475","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T16:54:45.221540Z","iopub.execute_input":"2024-05-22T16:54:45.222021Z","iopub.status.idle":"2024-05-22T16:54:45.262925Z","shell.execute_reply.started":"2024-05-22T16:54:45.221995Z","shell.execute_reply":"2024-05-22T16:54:45.261893Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'base_dir': '/kaggle/working',\n 'tokenizer_tgt': '/kaggle/input/2-ds-pretrain-model-bart/tokenizer/tokenizer_tgt.json',\n 'tokenizer_src': '/kaggle/input/2-ds-pretrain-model-bart/tokenizer/tokenizer_src.json',\n 'use_tokenizer': 'wordlevel',\n 'special_tokens': ['<s>', '</s>', '<pad>', '<unk>', '<mask>'],\n 'vocab_size': 30000,\n 'min_frequency': 2,\n 'model_folder': '/kaggle/working/model',\n 'model_basename': 'model_',\n 'model_bart_basename': 'bart_model_',\n 'preload': 'latest',\n 'data': '/kaggle/working/data',\n 'log_dir': '/kaggle/working/log',\n 'log_files': '/kaggle/working/log/log_files',\n 'loss_train': '/kaggle/working/log/log_files/loss_train.json',\n 'loss_val': '/kaggle/working/log/log_files/loss_val.json',\n 'loss_train_step': '/kaggle/working/log/log_files/loss_train_step.json',\n 'loss_val_step': '/kaggle/working/log/log_files/loss_val_step.json',\n 'timestep_train': '/kaggle/working/log/log_files/timestep_train.json',\n 'timestep_val': '/kaggle/working/log/log_files/timestep_val.json',\n 'timestep_train_and_val': '/kaggle/working/log/log_files/timestep_train_and_val.json',\n 'lang_src': 'noise_vi',\n 'lang_tgt': 'vi',\n 'train_ds': '/kaggle/input/2-ds-pretrain-model-bart/train.csv',\n 'val_ds': None,\n 'test_ds': None,\n 'corpus': None,\n 'max_len': 100,\n 'model_train': 'bart',\n 'step_train': None,\n 'pretrain': True,\n 'continue_step': False,\n 'batch_train': 28,\n 'batch_val': 28,\n 'batch_test': 1,\n 'num_steps': 60000,\n 'val_steps': 1200,\n 'd_model': 768,\n 'encoder_layers': 6,\n 'decoder_layers': 6,\n 'encoder_attention_heads': 12,\n 'decoder_attention_heads': 12,\n 'decoder_ffn_dim': 3072,\n 'encoder_ffn_dim': 3072,\n 'activation_function': 'gelu',\n 'dropout': 0.15,\n 'attention_dropout': 0.1,\n 'activation_dropout': 0.1,\n 'classifier_dropout': 0.0,\n 'max_position_embeddings': 100,\n 'init_std': 0.02,\n 'encoder_layerdrop': 0.0,\n 'decoder_layerdrop': 0.0,\n 'scale_embedding': False,\n 'num_beams': 4,\n 'checkpoint_bart_model': None,\n 'weight_decay': 0,\n 'lr': 0.3,\n 'eps': 1e-09,\n 'betas': (0.9, 0.98),\n 'label_smoothing': 0.01,\n 'warmup_steps': 4000,\n 'device': 'cuda',\n 'f_beta': 0.5,\n 'beams': [2]}"},"metadata":{}}]},{"cell_type":"code","source":"train.train(cf)","metadata":{"papermill":{"duration":5637.295027,"end_time":"2024-05-20T03:58:41.463049","exception":false,"start_time":"2024-05-20T02:24:44.168022","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T16:54:45.263959Z","iopub.execute_input":"2024-05-22T16:54:45.264213Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Created:\n/kaggle/working/model\n/kaggle/working/log\n/kaggle/working/log/log_files\n====================================\n/kaggle/input/2-ds-pretrain-model-bart/tokenizer/tokenizer_src.json\n/kaggle/input/2-ds-pretrain-model-bart/tokenizer/tokenizer_tgt.json\nRead tokenizer successfully\nCheck tokenizer src\n40000\nCheck tokenizer tgt\n50000\n====================================\nCheck BART model\nCustomBartModel(\n  (bart_model): BartModel(\n    (shared): Embedding(50000, 768, padding_idx=2)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50000, 768, padding_idx=2)\n      (embed_positions): BartLearnedPositionalEmbedding(102, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50000, 768, padding_idx=2)\n      (embed_positions): BartLearnedPositionalEmbedding(102, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (out): Linear(in_features=768, out_features=50000, bias=True)\n)\n====================================================\n/kaggle/input/2-ds-pretrain-model-bart/tokenizer/tokenizer_src.json\n/kaggle/input/2-ds-pretrain-model-bart/tokenizer/tokenizer_tgt.json\nRead tokenizer successfully\nCheck tokenizer src\n40000\nCheck tokenizer tgt\n50000\n====================================\nRead dataset successfully\nTrain dataset\n                                                  vi  \\\n0  Với việc ra mắt sàn thương mại điện tử dành ch...   \n1  Nếu theo đúng kế hoạch thì đầu tháng 6 sẽ là n...   \n2  Nhận được tin báo, cơ quan chức năng cùng ngườ...   \n3  Gia đình người mẹ nói thông qua luật sư biết h...   \n4  Có thể kiến nghị cho bà con xây dựng trên đất ...   \n\n                                            noise_vi  \n0  Với <mask> ra mắt sàn thương mại điện tử dành ...  \n1  Nếu theo đúng kế hoạch thì đầu tháng 6 sẽ là n...  \n2  Nhận <mask> tin báo, cơ <mask> chức năng cùng ...  \n3  Gia đình người mẹ nói thông qua luật sư biết h...  \n4  <mask> thể kiến <mask> <mask> bà <mask> xây dự...  \nVal dataset\n                                                  vi  \\\n0  035; Tổng số thí sinh có điểm trên sàn 4 khối ...   \n1  Các quan chức Chính phủ Ấn Độ cho biết sự khác...   \n2  Thanh Hóa, do nghi ngờ chị G có ngoại tình với...   \n3  Bên cạnh đó, Ban quản lý chợ đã phối hợp cùng ...   \n4  Bước 3: Sau khi tải về, ứng dụng sẽ yêu cầu ch...   \n\n                                            noise_vi  \n0  035; Tổng số thí sinh có <mask> trên sàn 4 khố...  \n1  Các quan chức Chính phủ Ấn Độ cho biết sự khác...  \n2  Thanh Hóa, <mask> nghi <mask> chị G có ngoại t...  \n3  Bên cạnh đó, <mask> đã phối <mask> Sở Công <ma...  \n4  Bước 3: Sau khi tải về, ứng dụng sẽ yêu cầu ch...  \nTest dataset\n                                                  vi  \\\n0  , sau đó tôi sẽ thảo luận với những người có l...   \n1  Trước năm 2000, nghề dệt lanh thổ cẩm ở Hà Gia...   \n2  Các ông Hoàng Văn Đức và Hà Thúc Nhật đã vi ph...   \n3  Tuy nhiên, để đảm bảo khắc phục những ảnh hưởn...   \n4  Mặt khác, theo bà Trang, có một điều rất quan ...   \n\n                                            noise_vi  \n0  , sau đó tôi sẽ thảo luận với <mask> người có ...  \n1  <mask> năm 2000, nghề dệt lanh thổ cẩm ở <mask...  \n2  <mask> ông <mask> <mask> Đức và Hà Thúc Nhật đ...  \n3  <mask> <mask> để đảm bảo khắc phục những ảnh h...  \n4  Mặt khác, theo bà Trang, có một điều rất quan ...  \n====================================\nGet dataloader successfully\nNo model to preload, start training from scratch\n/kaggle/input/2-ds-pretrain-model-bart/tokenizer/tokenizer_src.json\n/kaggle/input/2-ds-pretrain-model-bart/tokenizer/tokenizer_tgt.json\nRead tokenizer successfully\nCheck tokenizer src\n40000\nCheck tokenizer tgt\n50000\n====================================\nRead dataset successfully\nTrain dataset\n                                                  vi  \\\n0  Với việc ra mắt sàn thương mại điện tử dành ch...   \n1  Nếu theo đúng kế hoạch thì đầu tháng 6 sẽ là n...   \n2  Nhận được tin báo, cơ quan chức năng cùng ngườ...   \n3  Gia đình người mẹ nói thông qua luật sư biết h...   \n4  Có thể kiến nghị cho bà con xây dựng trên đất ...   \n\n                                            noise_vi  \n0  Với <mask> ra mắt sàn thương mại điện tử dành ...  \n1  Nếu theo đúng kế hoạch thì đầu tháng 6 sẽ là n...  \n2  Nhận <mask> tin báo, cơ <mask> chức năng cùng ...  \n3  Gia đình người mẹ nói thông qua luật sư biết h...  \n4  <mask> thể kiến <mask> <mask> bà <mask> xây dự...  \nVal dataset\n                                                  vi  \\\n0  035; Tổng số thí sinh có điểm trên sàn 4 khối ...   \n1  Các quan chức Chính phủ Ấn Độ cho biết sự khác...   \n2  Thanh Hóa, do nghi ngờ chị G có ngoại tình với...   \n3  Bên cạnh đó, Ban quản lý chợ đã phối hợp cùng ...   \n4  Bước 3: Sau khi tải về, ứng dụng sẽ yêu cầu ch...   \n\n                                            noise_vi  \n0  035; Tổng số thí sinh có <mask> trên sàn 4 khố...  \n1  Các quan chức Chính phủ Ấn Độ cho biết sự khác...  \n2  Thanh Hóa, <mask> nghi <mask> chị G có ngoại t...  \n3  Bên cạnh đó, <mask> đã phối <mask> Sở Công <ma...  \n4  Bước 3: Sau khi tải về, ứng dụng sẽ yêu cầu ch...  \nTest dataset\n                                                  vi  \\\n0  , sau đó tôi sẽ thảo luận với những người có l...   \n1  Trước năm 2000, nghề dệt lanh thổ cẩm ở Hà Gia...   \n2  Các ông Hoàng Văn Đức và Hà Thúc Nhật đã vi ph...   \n3  Tuy nhiên, để đảm bảo khắc phục những ảnh hưởn...   \n4  Mặt khác, theo bà Trang, có một điều rất quan ...   \n\n                                            noise_vi  \n0  , sau đó tôi sẽ thảo luận với <mask> người có ...  \n1  <mask> năm 2000, nghề dệt lanh thổ cẩm ở <mask...  \n2  <mask> ông <mask> <mask> Đức và Hà Thúc Nhật đ...  \n3  <mask> <mask> để đảm bảo khắc phục những ảnh h...  \n4  Mặt khác, theo bà Trang, có một điều rất quan ...  \n====================================\nGet dataloader successfully\n","output_type":"stream"},{"name":"stderr","text":"Trainning:   1%|          | 361/32036 [02:11<3:13:50,  2.72it/s, loss=7.615, global_step=0000000360] ","output_type":"stream"}]},{"cell_type":"code","source":"test.test(cf)","metadata":{"papermill":{"duration":475.873008,"end_time":"2024-05-20T04:06:40.756315","exception":false,"start_time":"2024-05-20T03:58:44.883307","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}